grid.arrange(a3, b3, c3, nrow = 3)
X_train_subset <- model.matrix(RainTomorrow~., data=rain_subset_train)
X_test_subset <- model.matrix(RainTomorrow~., data=rain_subset_test)
X_train_subset <- X_train_subset[,-1]
X_test_subset <- X_test_subset[,-1]
# Target vector
y_train_subset <- rain_subset_train$RainTomorrow
y_test_subset <- rain_subset_test$RainTomorrow
set.seed(123)
#We're first implementing lasso/ridge with balanced data with no feature
#selection
X <- model.matrix(RainTomorrow ~ ., data = rain_balanced)
X <- X[, -1]
X_train <- model.matrix(RainTomorrow ~ ., data = rain_balanced_train)
X_test <- model.matrix(RainTomorrow ~ ., data = rain_balanced_test)
X_train <- X_train[, -1]
X_test <- X_test[, -1]
# Target vector
y <- rain_balanced$RainTomorrow
y_train <- rain_balanced_train$RainTomorrow
y_test <- rain_balanced_test$RainTomorrow
# alpha=0 for ridge, alpha=1 (default) for lasso
# Ridge Regression (L2)
ridge_cv <-
cv.glmnet(
X_train,
y_train,
alpha = 0,
family = "binomial",
type.measure = "class"
)
plot(ridge_cv)
# To select best lambda
lambda_opt_ridge <- ridge_cv$lambda.min
lambda_opt_ridge
pred_ridge <-
predict(ridge_cv, X_test, type = "class", s = lambda_opt_ridge)
error_ridge <- mean(pred_ridge != y_test) # 0.2133891
accuracy_ridge <- mean(pred_ridge == y_test) # 0.7866109
cm_ridge <-
confusionMatrix(
data = factor(pred_ridge),
reference = factor(y_test),
mode = 'everything'
) # F1 : 0.7856
#Lasso Regression (L1)
lasso_cv <-
cv.glmnet(
X_train,
y_train,
alpha = 1,
family = "binomial",
type.measure = "class"
)
plot(lasso_cv)
lambda_opt_lasso <- lasso_cv$lambda.min
lambda_opt_lasso
pred_lasso <-
predict(lasso_cv, X_test, type = "class", s = lambda_opt_lasso)
error_lasso <- mean(pred_lasso != y_test) # 0.2046991
accuracy_lasso <- mean(pred_lasso == y_test) #  0.7953009
cm_lasso <-
confusionMatrix(
data = factor(pred_lasso),
reference = factor(y_test),
mode = 'everything'
) # F1 : 0.7956
#Then, we implemented Ridge and LASSO after feature selection
# Ridge Regression (L2)
ridge_cv_subset <-
cv.glmnet(
X_train_subset,
y_train_subset,
alpha = 0,
family = "binomial",
type.measure = "class"
)
plot(ridge_cv_subset)
# To select best lambda
lambda_opt_ridge_subset <- ridge_cv_subset$lambda.min
lambda_opt_ridge_subset
pred_ridge_subset <-
predict(ridge_cv_subset, X_test_subset, type = "class",
s = lambda_opt_ridge_subset)
error_ridge_subset <-
mean(pred_ridge_subset != y_test_subset) # 0.2125845
accuracy_ridge_subset <-
mean(pred_ridge_subset == y_test_subset) # 0.7874155
cm_ridge_subset <-
confusionMatrix(
data = factor(pred_ridge_subset),
reference = factor(y_test),
mode = 'everything'
) # F1 : 0.7864
#Lasso Regression (L1)
lasso_cv_subset <-
cv.glmnet(
X_train_subset,
y_train_subset,
alpha = 1,
family = "binomial",
type.measure = "class"
)
plot(lasso_cv_subset)
lambda_opt_lasso_subset <- lasso_cv_subset$lambda.min
lambda_opt_lasso_subset
pred_lasso_subset <-
predict(lasso_cv_subset, X_test_subset, type = "class",
s = lambda_opt_lasso_subset)
error_lasso_subset <-
mean(pred_lasso_subset != y_test_subset) # 0.2059865
accuracy_lasso_subset <-
mean(pred_lasso_subset == y_test_subset) # 0.7940135
cm_lasso_subset <-
confusionMatrix(
data = factor(pred_lasso_subset),
reference = factor(y_test),
mode = 'everything'
) # F1 : 0.7941
#looking for outliers in our data after balancing and feature selection
g1<- ggplot(data = rain_subset_train, aes(y = MinTemp,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("Min Temperature")
chisq.out.test(rain_subset_train$MinTemp)  #p-value = 0.00151, remove 376
which(rain_subset_train$MinTemp == 0)
g2<- ggplot(data = rain_subset_train, aes(y = Sunshine,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("Sunshine")
chisq.out.test(rain_subset_train$Sunshine)  #p-value = 0.04431, index 6965
which(rain_subset_train$Sunshine == 1)
g3<- ggplot(data = rain_subset_train, aes(y = WindGustSpeed,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("WindGustSpeed")
chisq.out.test(rain_subset_train$WindGustSpeed) #p-value = 3.071e-07, no values
which(rain_subset_train$WindGustSpeed == 0.939130434782609)
g4<- ggplot(data = rain_subset_train, aes(y = WindSpeed9am,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("WindSpeed9am")
chisq.out.test(rain_subset_train$WindSpeed9am)  #p-value = 1.43e-08 , no values
which(rain_subset_train$WindSpeed9am == 0.969230769230769)
g5<- ggplot(data = rain_subset_train, aes(y = WindSpeed3pm,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("WindSpeed3pm")
chisq.out.test(rain_subset_train$WindSpeed3pm)  #p-value = 4.733e-07 , no values
which(rain_subset_train$WindSpeed3pm == 0.851351351351351)
g6<- ggplot(data = rain_subset_train, aes(y = Humidity3pm,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("Humidity3pm")
chisq.out.test(rain_subset_train$Humidity3pm)
#p-value = 0.009785, #indices:3782 10189 10959 15362 16105 18240
which(rain_subset_train$Humidity3pm ==0.01)
g7<- ggplot(data = rain_subset_train, aes(y = Pressure9am,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("Pressure9am")
chisq.out.test(rain_subset_train$Pressure9am) # p-value = 2.435e-06, index= 1935
which(rain_subset_train$Pressure9am ==0.0283806343906518)
g8<- ggplot(data = rain_subset_train, aes(y = Pressure3pm,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("Pressure3pm")
chisq.out.test(rain_subset_train$Pressure3pm)  # p-value = 2.756e-07, index=15369
which(rain_subset_train$Pressure3pm ==0)
g9<- ggplot(data = rain_subset_train, aes(y = Cloud9am,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("Cloud9am")
chisq.out.test(rain_subset_train$Cloud9am)
# we got a p-value of 0.07 so we cannot refute the null hypothesis
g10<- ggplot(data = rain_subset_train, aes(y = Cloud3pm,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("Cloud3pm")
chisq.out.test(rain_subset_train$Cloud3pm) #p-value = 0.04988
g11<- ggplot(data = rain_subset_train, aes(y = Temp3pm,fill = 2)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 16,
outlier.size = 2)+
theme(legend.position="none") +
ylab("Temp3pm")
chisq.out.test(rain_subset_train$Temp3pm)
#p-value = 0.0003997, indices= 4596, 10679
which(rain_subset_train$Temp3pm ==1)
grid.arrange(g1, g2, g3,g4,g5,g6,g7,g8,g9,g10,g11,  nrow = 3)
#remove outliers for p_values less that 0.05
rain_subset_train_NoOutliers <- rain_subset_train[-c(4596,10679,15369,1935,3782,
10189,10959,15362,16105,
18240,376,6965)]
# Model definition starting from the previous glm_bal model:
lda <-
lda(data = rain_subset_train_NoOutliers, RainTomorrow ~ ., family = "binomial")
lda
pred_lda <- predict(lda, rain_subset_test, type = "response")
post_lda <- pred_lda$posterior
pred_lda_04 <- as.factor(ifelse(post_lda[, 2] > threshold4, 1, 0))
pred_lda_05 <- as.factor(ifelse(post_lda[, 2] > threshold5, 1, 0))
pred_lda_06 <- as.factor(ifelse(post_lda[, 2] > threshold6, 1, 0))
# Confusion matrix with threshold = 0.4
error_lda4 <- mean(pred_lda_04 != rain_subset_test$RainTomorrow)
accuracy_lda4 <- mean(pred_lda_04 == rain_subset_test$RainTomorrow)
lda_CM04 <-
confusionMatrix(
data = factor(pred_lda_04),
reference = factor(rain_subset_test$RainTomorrow),
mode = 'everything'
)
# Confusion matrix with threshold = 0.5
error_lda5 <- mean(pred_lda_05 != rain_subset_test$RainTomorrow)
accuracy_lda5 <- mean(pred_lda_05 == rain_subset_test$RainTomorrow)
lda_CM05 <-
confusionMatrix(
data = factor(pred_lda_05),
reference = factor(rain_subset_test$RainTomorrow),
mode = 'everything'
)
# Confusion matrix with threshold = 0.6
error_lda6 <- mean(pred_lda_06 != rain_subset_test$RainTomorrow)
accuracy_lda6 <- mean(pred_lda_06 == rain_subset_test$RainTomorrow)
lda_CM06 <-
confusionMatrix(
data = factor(pred_lda_06),
reference = factor(rain_subset_test$RainTomorrow),
mode = 'everything'
)
A <-
create_confusion_matrix(lda_CM04, 0.4, error_lda4, accuracy_lda4)
B <-
create_confusion_matrix(lda_CM05, 0.5, error_lda5, accuracy_lda5)
C <-
create_confusion_matrix(lda_CM06, 0.6, error_lda6, accuracy_lda6)
# Threshold of 0.6 is the best among thresholds in terms of accuracy,
#sensitivity, and specificity
CM_all_lda = list(A, B, C)
plot_width <- c(4, 4, 4)
grid.arrange(grobs = CM_all_lda,
nrow = 3,
width = plot_width)
# Here we plot stacked histograms representing the linear combination of
# variable that best represent the samples with their discriminant scores, split
#by each assigned class. The y-axis is the frequency of examples falling into
# each range of discriminant scores. From these plots, we observed little to no
# overlap across the two classes, which is an indicator of good separation
# between the two classes.
ldahist(pred_lda$x[, 1], g = pred_lda$class, col = 2)
qda <-
qda(data = rain_subset_train_NoOutliers, RainTomorrow ~ ., family = "binomial")
qda
pred_qda <- predict(qda, rain_subset_test, type = "response")
post_qda <- pred_qda$posterior
pred_qda_04 <- as.factor(ifelse(post_qda[, 2] > threshold4, 1, 0))
pred_qda_05 <- as.factor(ifelse(post_qda[, 2] > threshold5, 1, 0))
pred_qda_06 <- as.factor(ifelse(post_qda[, 2] > threshold6, 1, 0))
# Confusion matrices and performance metrics below indicate very little
#difference across the QDA models with the different thresholds.
# Confusion matrix with threshold = 0.4
error_qda4 <- mean(pred_qda_04 != rain_subset_test$RainTomorrow)
accuracy_qda4 <- mean(pred_qda_04 == rain_subset_test$RainTomorrow)
qda_CM04 <-
confusionMatrix(
data = factor(pred_qda_04),
reference = factor(rain_subset_test$RainTomorrow),
mode = 'everything'
)
# Confusion matrix with threshold = 0.5
error_qda5 <- mean(pred_qda_05 != rain_subset_test$RainTomorrow)
accuracy_qda5 <- mean(pred_qda_05 == rain_subset_test$RainTomorrow)
qda_CM05 <-
confusionMatrix(
data = factor(pred_qda_05),
reference = factor(rain_subset_test$RainTomorrow),
mode = 'everything'
)
# Confusion matrix with threshold = 0.6
error_qda6 <- mean(pred_qda_06 != rain_subset_test$RainTomorrow)
accuracy_qda6 <- mean(pred_qda_06 == rain_subset_test$RainTomorrow)
qda_CM06 <-
confusionMatrix(
data = factor(pred_qda_06),
reference = factor(rain_subset_test$RainTomorrow),
mode = 'everything'
)
A <-
create_confusion_matrix(qda_CM04, 0.4, error_qda4, accuracy_qda4)
B <-
create_confusion_matrix(qda_CM05, 0.5, error_qda5, accuracy_qda5)
C <-
create_confusion_matrix(qda_CM06, 0.6, error_qda6, accuracy_qda6)
# Threshold of 0.05 is the best among thresholds in terms of accuracy,
# sensitivity, and specificity
CM_all_qda = list(A, B, C)
plot_width <- c(4, 4, 4)
grid.arrange(grobs = CM_all_qda,
nrow = 3,
width = plot_width)
set.seed(2531)
# We look now for the best value of the parameter
kmax <- 100
knn_test_error <- numeric(kmax)
# For each possible value of k we consider the obtained accuracy of the model
for (k in 1:kmax)
{
knn_pred <-
as.factor(knn(X_train_subset, X_test_subset, cl = y_train_subset, k = k))
cm <- confusionMatrix(data = knn_pred, reference = y_test_subset)
knn_test_error[k] <- 1 - cm$overall[1]
}
# We took the minimum value of the error
k_min <- which.min(knn_test_error)
k_min
# We compute now the prediction with the value of k that gives us the minimum error
knn <-
knn(X_train_subset, X_test_subset, cl = y_train_subset, k = k_min)
knn_pred_min <- knn
# Confusion matrix for KNN on the test set
cm_knn <-
confusionMatrix(data = knn_pred_min ,
reference = rain_subset_test$RainTomorrow,
mode = 'everything')
cm_table_knn <- as.data.frame(cm_knn$table)
f1_score_knn <- cm_knn$byClass["F1"]
error_knn <- mean(knn_pred_min != rain_subset_test$RainTomorrow)
accuracy_knn <- mean(knn_pred_min == rain_subset_test$RainTomorrow)
ggplot(data = cm_table_knn, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile(color = "white") +
geom_text(aes(label = Freq), color = "black", size = 8) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(
title = paste(
"Confusion Matrix for KNN with F1-Score:",
round(f1_score_knn, 3),
"Error:",
round(error_knn, 3) ,
"Accuracy:",
round(accuracy_knn, 3)
),
x = "Target",
y = "Prediction"
) +
theme_minimal() +
theme(axis.text = element_text(size = 8),
plot.title = element_text(size = 8, face = "bold"))
#Plot test error against different levels of K
ggplot(data.frame(knn_test_error),
aes(x = 1:kmax, y = knn_test_error)) +
geom_line(colour="blue") +
geom_point(colour="red") +
xlab("K (#neighbors)") +
ylab("Test error") +
ggtitle(paste0("Best value of K = ", k_min,
" (minimal error = ",
format((knn_test_error[k_min])*100, digits = 4),
"%)"))
# Best Models:
set.seed(125)
# GLM Model
best_glm_model <- glm_model
best_glm_predict <- glm_predict
# LDA Model
best_lda_model <-
lda(data = rain_subset_train, RainTomorrow ~ ., family = "binomial")
best_lda_predict <-
predict(lda, rain_subset_test, type = "response")
best_post_lda <- best_lda_predict$posterior
# QDA Model
best_qda_model <-
qda(data = rain_subset_train, RainTomorrow ~ ., family = "binomial")
best_qda_predict <-
predict(qda, rain_subset_test, type = "response")
best_post_qda <- best_qda_predict$posterior
# LASSO Model
best_lasso_model <- lasso_cv_subset
best_lasso_predict <- pred_lasso_subset
# Ridge Model
best_ridge_model <- ridge_cv_subset
best_ridge_predict <- pred_ridge_subset
prediction <-
tibble(truth = as.factor(rain_subset_test$RainTomorrow))
prediction <-
prediction %>% mutate(pred = as.numeric(best_glm_predict)) %>%
mutate(model = "GLM") %>%
add_row(
truth = as.factor(rain_subset_test$RainTomorrow),
pred = as.numeric(best_post_lda[, 2]),
model = "LDA"
) %>%
add_row(
truth = as.factor(rain_subset_test$RainTomorrow),
pred = as.numeric(best_post_qda[, 2]),
model = "QDA"
) %>%
add_row(
truth = as.factor(rain_subset_test$RainTomorrow),
pred = as.numeric(best_ridge_predict),
model = "Ridge"
) %>%
add_row(
truth = as.factor(rain_subset_test$RainTomorrow),
pred = as.numeric(best_lasso_predict),
model = "Lasso"
)
# Calculate ROC curves for each model
roc_list <-
lapply(split(prediction, prediction$model), function(df) {
roc.out <- roc(df$truth, df$pred, levels = c(0, 1))
roc.df <- data.frame(specificity = roc.out$specificities,
sensitivity = roc.out$sensitivities)
return(roc.df)
})
model_colors <- c("red", "blue", "green", "orange", "black")
#List of Model Names
model_names <- names(roc_list)
ggplot() +
lapply(seq_along(roc_list), function(i) {
geom_line(
data = roc_list[[i]],
aes(
x = 1 - specificity,
y = sensitivity,
color = model_colors[i]
),
linetype = "solid",
linewidth = 0.7
)
}) +
lapply(seq_along(roc_list), function(i) {
labs(
title = "ROC Curves",
x = "False Positive Rate",
y = "True Positive Rate",
color = "Models"
)
}) +
scale_color_manual(values = model_colors, labels = model_names) +
theme_minimal()
file_path3 <- "/Users/Sofia/Desktop/Rain_Australia/metrics_summary.csv"
metrics_summary <- read.csv(file_path3)
options(knitr.kable.NA = '')
metrics_summary %>%
knitr::kable(
format = "latex",
align = "l",
booktabs = TRUE,
longtable = TRUE,
linesep = "",
caption = "Table of performance metrics by model."
) %>% row_spec(0,bold=TRUE) %>%
kableExtra::kable_styling(
position = "left",
latex_options = c("striped", "repeat_header"),
stripe_color = "gray!15"
)
?fpp2
install.packages("fpp2")
install.packages("forecast")
install.packages("lmtest")
install.packages("DIMORA")
library(tidyverse)
library(knitr)
library(ggplot2)
library(dplyr)
# model libraries
library(lmtest)
library(forecast)
library(DIMORA)
library(fpp2)
?tidyverse
?dplyr
?lmtest
View(mcycle)
install.packages("lmtest")
install.packages("forecast")
?lmtest
?forecast
?DIMORA
?fpp2
setwd("/Users/Sofia/Desktop/Education/UNIPD/Fall 2023/Business Economic and Financial Data/project/data")
? ts()
setwd("/Users/Sofia/Desktop/Education/UNIPD/Fall 2023/Business Economic and Financial Data/project/data")
library(ggplot2)
library(dplyr)
# model libraries
library(lmtest)
library(forecast)
library(DIMORA)
library(fpp2)
# read data
data <- read_csv("energy_data.csv")
View(data)
? read_csv
data <- read_csv("energy_data.csv", sep = ";")
data <- read_delim("energy_data.csv", delim = ";")
head(data)
View(data)
str(data)
summary(data)
View(data)
colnames(data)
